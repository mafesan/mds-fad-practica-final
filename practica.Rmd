---
title: <center> Práctica Métodos de Análisis de Datos </center>
subtitle: <center>APPSTORE - APPLE</center>
author: <center>Edgli Morales, David Ruiz y Miguel Ángel Fernández - Máster en Data Science, URJC</center>
date: <center>Diciembre de 2019</center>
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_folding: hide
    theme: cosmo
  pdf_document: default
---
<style>
  body {
    text-align: justify
  }
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r init, include=FALSE}
# Cargamos los paquetes que vamos a usar en el informe
library(dplyr)
library(tidyr)
library(ggplot2)

library(knitr)
library(kableExtra)

library(VIM)
library(mice)

library(leaps)
library(dummies)

library(data.table)
library(tidyverse)
library(R.utils)

library(lmtest)
library(corrplot)
library(wesanderson)

library(GGally)

# Semilla inicial
set.seed(1)
```

# Introducción

El conjunto de datos que se analiza en esta práctica trata sobre información acerca de aplicaciones móviles disponibles en el *App Store*, la tienda de aplicaciones de *Apple*.

En esta práctica se pretende analizar sus variables con el fin de plantear objetivos que aporten valor, utilizando las técnicas principales para el análisis y modelado de datos.

# Análisis exploratorio inicial - EDA

```{r read_file}
data_apps_all = read.csv('AppleStore.csv')
```

Cargamos el conjunto datos y mostramos una vista preliminar de los tipos de variables que contiene. Observamos que el data set consta de 7197 observaciones y 17 variables:

```{r}
dim(data_apps_all)
```

Con la función head visualizamos las primeras 10 filas del conjunto de datos, incluyendo el nombre de las variables y algunos de los valores que contiene cada una:

```{r}
head(data_apps_all)
```

## Tipo de Variables

Las variables de este conjunto se pueden agrupar de la siguiente manera según el tipo de sus valores:

* Variables Cuantitativas: 11
  * Discretas: 10
  * Continuas: 1
* Variables Categóricas: 6

| VARIABLE           | DESCRIPCIÓN                                                                  | TIPO DE VARIABLE      	|
| ------------------ | ---------------------------------------------------------------------------- | ----------------------- |
| X                  | Indice                                                                    	  | Cuantitativa Discreta  	|
| id                 | "Apple ID", Número de identificación de la app en iTunes                     | Cuantitativa Discreta   |
| track_name         | Nombre de la aplicación                                                   	  | Categórica            	|
| size_bytes         | Tamaño de la aplicación en bytes                                            	| Cuantitativa Discreta 	|
| currency           | Tipo de Moneda (divisa)                                                      | Categórica            	|
| price              | Precio                                                                    	  | Cuantitativa Continua 	|
| rating_count_tot   | Cantidad de Reseñas de usuario para todas las versiones                      | Cuantitativa Discreta 	|
| rating_count_ver   | Cantidad de Reseñas de usuario para la última versióon de la aplicación      | Cuantitativa Discreta	  |
| user_rating        | Valor promedio de las Reseñas Totales                                     	  | Cuantitativa Discreta 	|
| user_rating_ver 	 | Valor promedio de las Reseñas para la última versión                      	  | Cuantitativa Discreta 	|
| ver                | Última versión                                                           	  | Categórica            	|
| cont_rating        | Calificación del contenido (Edad)                                         	  | Categórica            	|
| prime_genre        | Genero principal de la aplicación                                            | Categórica            	|
| sup_devices.num    | Número de dispositivos soportados                                         	  | Cuantitativa Discreta 	|
| ipadSc_urls.num    | Número de capturas de pantalla mostrados antes del acceso a la aplicación 	  | Cuantitativa Discreta 	|
| lang.num           | Número de idiomas soportados                                                 | Cuantitativa Discreta 	|
| vpp_lic            | Licencia de compras por Volumen de Apple activa (Vpp Device Based Licensing) | Categórica (Binaria)  	|

Hay que añadir que las variables `user_rating` y `user_rating_ver` las hemos considerado como discretas ya que el valor que pueden tomar va de 0 a 5, en saltos de 0.5, ya que esta puntuación se representa por estrellas (0 estrellas, media estrella sería 0.5, 1 estrella, etc.).

## Correlación

```{r, warning= FALSE, fig.align='center', fig.show='hold',fig.width=18, fig.height=14, echo=FALSE, message=FALSE}
data_cor <- select_if(data_apps_all, is.numeric)
data_cor <- select(data_cor, -c(1))
corrplot(cor(data_cor), method = "color", addCoef.col="grey", order = "AOE", tl.cex=2, number.cex = 2)
```

Al observar la matriz de correlación apreciamos que la mayoría de las variables no se relacionan linealmente a un nivel significativo, si resaltaremos las que guardan cierta correlación positiva:

* `size_bytes` vs `sup_devices num`: Cuando una aplicación está soportada por más dispositivos, su tamaño tiende a aumentar.

* `size_bytes` vs `ipadSc_urls.num`: El tamaño de la aplicación puede estar relacionado con el número de capturas de pantalla que presenta la aplicación.

* `lang.num` vs `user_rating_ver`: La cantidad de idiomas soportados influye sobre las puntuaciones de las ultimas versiones.

* `lang.num` vs `user_rating`: Al igual que la anterior, la cantidad de idiomas soportados influye sobre las valoraciones.

* `lang.num` vs `rating_count_tot`: El número de idiomas soportados se relaciona con el número de calificaciones total que recibe.

* `ipadSc_urls.num` vs `user_rating_ver`: El número de capturas de pantalla o *screenshots* con la puntuación de la última versión de la aplicación.

```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=8, fig.height=6, echo=FALSE, message=FALSE}
stats_apps_cor <-
  data_apps_all%>%
  select(id, size_bytes,rating_count_tot, rating_count_ver, user_rating, user_rating_ver, sup_devices.num,ipadSc_urls.num, lang.num)
ggpairs(stats_apps_cor)
```

# Definición de objetivos

Al observar las variables con las que cuenta el dataset, nos resulta interesante la variable `rating_count_tot` la cual contabiliza el numero de calificaciones y/o reseñas que ha recibido la aplicación.

Aunque no tenemos el dato del número de descargas, la variable `rating_count_tot` seguramente tendrá una correlación fuerte con el dato del número de descargas (dato que no facilita Apple de manera pública); lo que se conoce como variable proxy.

Podemos asumir que el número de calificaciones que ha recibido la aplicación corresponde a un número de usuarios que ha descargado la aplicación y que además es un usuario activo de dicha aplicación, por lo que esta variable nos resulta interesante como una aproximación de su número de descargas.

Dicho esto, el objetivo general que nos gustaría alcanzar analizando este conjunto de datos es **Obtener un modelo que prediga cuántas descargas va a obtener una aplicación en función de una serie de variables**. Además, buscamos encontrar qué variables son relevantes a la hora de obtener más o menos reseñas.
Además de este objetivo principal, surgen unos cuantos objetivos secundarios como relaciones entre variables que pueden ser interesantes. Por ejemplo:

* ¿Está relacionado el número de idiomas a los que la aplicación está traducida con su valoración y el número de valoraciones?
* ¿Influye el número de capturas de pantalla que se adjuntan en la pantalla de descarga?
* ¿A qué género pertenecen las aplicaciones más y menos valoradas?

Al observar el top 10 de aplicaciones con el mayor número de calificaciones corroboramos que el numero de usuarios que califican la aplicación se corresponde a las variables con mas "éxito" en la actualidad en cuanto a número de usuarios activos.

```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=8, fig.height=5, echo=FALSE, message=FALSE}
top_10 <- data_apps_all %>% top_n(10,rating_count_tot)

orden = top_10$rating_count_tot %>% order(decreasing = T)
orden
top_10$track_name = factor(top_10$track_name, levels = top_10$track_name[orden])


ggplot(top_10, aes(x=top_10$track_name , y=top_10$rating_count_tot))+
  geom_bar(stat = 'identity', fill='steelblue3')+
  labs(x = "Nombre de la APP", y = "Num Total de Calificaciones", title = "APP VS")+
  theme(plot.title = element_text(hjust = 0.5, face="bold", size =14), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 12, angle = 45, hjust = 1), axis.text.y = element_text(size = 12))
```

Al observar el top 10 de aplicaciones con el mayor número de calificaciones corroboramos que el numero de usuarios que califican la aplicación se corresponde a las variables con mas "éxito" en la actualidad en cuanto a número de usuarios activos.

```{r}
data_apps_unrated <- data_apps_all %>%
  filter(rating_count_tot == 0)

data_apps <- data_apps_all %>%
  filter(rating_count_tot > 0)
```

Relacionamos nuestra variable de interes con las variables anteriormente mencionadas como objetivos secundarios de la practica, asi determinar mas adelante su influencia en el modelo y si


```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=8, fig.height=3, echo=FALSE, message=FALSE}
data_apps_all %>% group_by(prime_genre) %>% 
  summarise(tot_rating = sum(rating_count_tot)) %>% 
  mutate(prime_genre = factor(prime_genre, levels = prime_genre[order(tot_rating, decreasing = T)])) %>% 
  ggplot(., aes(x=prime_genre, y=tot_rating, fill=prime_genre))+
  geom_bar(stat = 'identity')+
  labs(x = "Genero de la APP", y = "Num Total de Calificaciones", title="Número de calificaciones vs Genero de la aplicación" )+
  theme(plot.title = element_text(hjust = 0.5, face="bold", size =14), axis.text.x = element_text(size = 8, angle = 45, hjust = 1), axis.text.y = element_text(size = 8), legend.position = "none")
```

Observamos que las aplicaciones con mayor **numero de calificaciones** corresponden a Games y Social Networks.


```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=8, fig.height=3, echo=FALSE, message=FALSE}
data_apps_all %>% group_by(lang.num) %>% 
  summarise(tot_rating = sum(rating_count_tot)) %>% 
  mutate(lang.num = factor(lang.num, levels = lang.num[order(tot_rating, decreasing = T)])) %>% 
  ggplot(., aes(x=lang.num, y=tot_rating, fill=lang.num))+
  geom_bar(stat = 'identity')+
  labs(x = "Idiomas a los que se encuentra traducida la APP", y = "Número de calificaciones" , title="Número de calificaciones vs Idiomas" )+
  theme(plot.title = element_text(hjust = 0.5, face="bold", size =14), axis.text.x = element_text(size = 8, hjust = 1.5, angle= 45), axis.text.y = element_text(size = 8),legend.position = "none")
```

Cuando observamos esta gráfico observamos que el comportamiento es un tanto peculiar, la mayoría de las aplicaciones con mayor numero de calificaciones se mantienen entre 1-10 idiomas, mientras que las que se encuentran traducidas a mas de 50 idiomas no. Lo que nos lleva a pensar que esta variable no esta directamente relacionada con nuestra variable de interés, sin embargo, lo que si esta directamente relacionado es que ese idioma aunque fuese 1-2 son los idiomas que mas demandan tienen en el mercado: Ingles, chino, etc… 
  select(price:user_rating_ver, ipadSc_urls.num,

         sup_devices.num, lang.num, size_bytes)
```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=8, fig.height=3, echo=FALSE, message=FALSE}
ggpairs(stats_apps_cor)
data_apps_all %>% group_by(ipadSc_urls.num) %>% 
  summarise(tot_rating = sum(rating_count_tot)) %>% 
  mutate(ipadSc_urls.num = factor(ipadSc_urls.num, levels = ipadSc_urls.num[order(tot_rating, decreasing = T)])) %>% 
  ggplot(., aes(x=ipadSc_urls.num, y=tot_rating, fill=ipadSc_urls.num))+
  geom_bar(stat = 'identity')+
  labs(x = "Captura de Pantalla de la APP antes de descargarla", y = "Num Total de Calificaciones", title="Número de calificaciones vs Captura de Pantalla de la APP" )+
  theme(plot.title = element_text(hjust = 0.5, face="bold", size =14),axis.text.x = element_text(size = 8, hjust = 1), axis.text.y = element_text(size = 8),legend.position = "none")
```

En este caso, las aplicaciones con mayor numero de capturas consiguen mayor numero de calificaciones (numero de descargas) sin embargo, podemos ver que el numero de las siguientes son 0. Al observar este dato, investigamos la dinámica y el proceso de una app para tener ScreenShot en el AppleStore; si es cierto que para la fecha Julio 2017, Apple aún permitía lanzar aplicaciones sin Capturas de Pantalla y con un máximo de 5. En la actualidad se permiten hasta un máximo de 10 por demanda de los desarrolladores de aplicaciones.


# Generar conjuntos de entrenamiento, test y validación

Separamos el número de observaciones en dos bloques: el de Training (un 75\%) y el de Test (un 25\%). 
Además, para realizar una simulación de lo que ocurrirá al probar los datos de Test, dividimos el conjunto de Training para obtener también un conjunto de validación, por lo que la proporción queda de la siguiente manera respecto del número total de observaciones:

* Training: 50\%
* Validación: 25\%
* Test: 25\%

```{r separar_training_test}
# Semilla
set.seed(1)

# Separamos los datos en los siguientes porcentajes: Train (50), Test (25), Validación (25)

# Obtenemos la muestra del 50% y filtramos por esos elementos
train = sample(1:nrow(data_apps), .5 * nrow(data_apps), replace = FALSE)
data_train = data_apps[train,]

# Cogemos el 50% restante y lo dividimos en dos partes iguales para Test y para Validación
test_validacion = data_apps[-train,]
test = sample(1:nrow(test_validacion), .5 * nrow(test_validacion), replace = FALSE)

# Filtramos para obtener los otros dos conjuntos
data_test = test_validacion[test,]
data_validacion = test_validacion[-test,]
```


# Detección, tratamiento e imputación de datos faltantes

Al realizar un análisis preliminar de los datos, observamos que no hay valores faltantes a primera vista.
```{r comprobar_na}
sum(is.na(data_train))
```

Sin embargo, observamos que hay variables que contienen valores que no tienen sentido para dicha variable. Por ejemplo, en la variable
`lang.num` correspondiente al número de idiomas de la aplicación, hay observaciones cuyo valor es 0 y su valor mínimo debería ser 1 (la aplicación debe estar al menos disponible en un idioma). Aunque son pocas, también ocurre en aplicaciones conocidas (como juegos) que sabemos que sí están disponibles al menos en 1 o 2 idiomas, por lo que hemos decidido convertir estos valores en NA para imputarlos posteriormente.

```{r}
data_train <- data_train %>%
     mutate(lang.num=replace(lang.num, lang.num==0, NA))
```

Como estos valores faltantes no son suficientes, vamos a simularlos para algunas de las variables. Primero, vamos a generar un gran porcentaje de valores faltantes en una de las variables, "`currency`", que indica la divisa del precio de la aplicación. El porcentaje de valores faltantes será en este caso de un 80\%.

```{r generate_missing_currency}
# Semilla
set.seed(1)

num_filas <- nrow(data_train)
porcentaje_missing <- 80
num_missing <- round((num_filas * porcentaje_missing)/100)
pos_missing <- sort(sample(1:num_filas, num_missing, replace=FALSE))

data_train$currency[c(pos_missing)] <- NA
```

Aunque en los datos originales todos los valores de esta columna son `USD` (dólares estadounidenses), simulamos que nos faltan tantos valores de esta variable que la hace prácticamente inusable en cuanto a la información que nos proporciona.

En una situación en la que tenemos datos del precio pero no sabemos la divisa en la que está ese valor, hemos decidido crear una variable categorizando las aplicaciones como gratuitas o de pago.

A continuación, generamos valores faltantes en las variables `user_rating` y `user_rating_ver`, que describen la valoración media de los usuarios en estrellas (valor de 0 a 5) para todas las versiones de la aplicación y sólo para la última versión, respectivamente.

En este caso, generamos un 12\% de valores faltantes para `user_rating` y un 8% para `user_rating_ver`.

```{r generate_missing_user_rating}
# Semilla
set.seed(1)

data_train_original <- data_train

num_filas <- nrow(data_train)
porcentaje_missing <- 12
num_missing <- round((num_filas * porcentaje_missing)/100)

pos_missing <- sort(sample(1:num_filas, num_missing, replace=FALSE))
data_train$user_rating[c(pos_missing)] <- NA

porcentaje_missing <- 8
num_missing <- round((num_filas * porcentaje_missing)/100)

pos_missing <- sort(sample(1:num_filas, num_missing, replace=FALSE))
data_train$user_rating_ver[c(pos_missing)] <- NA
```

Una vez que hemos generado los valores faltantes, vamos a representar estos valores en un histograma y cómo se distribuyen en el conjunto.

```{r repr_valores_missing, echo=FALSE, message=TRUE, warning=FALSE}
aggr_plot <- aggr(data_train, col=c('steelblue','coral'), numbers=TRUE, sortVars=TRUE,
                  labels=names(data_train), cex.axis=.7, gap=3,
                  ylab=c("Histograma de datos faltantes","Patrón"))
```

En el histograma (gráfico de la izquierda), observamos que la proporción de valores faltantes coincide con los valores que hemos generado. En el gráfico de la derecha podemos ver cuál es la propoción de que falten valores siguiendo una combinación de variables. Por ejemplo, en la primera fila está el porcentaje de filas que contienen faltantes en las variables `user_rating` y `user_rating_ver` a la vez.

A continuación, vemos un gráfico que representa cómo están distribuídos los valores faltantes de estas dos variables y cuál es el rango de sus valores, incluyendo su media y su mediana:

```{r repr_variables_missing}
data_train %>%
    select(user_rating, user_rating_ver) %>%
    marginplot()
```

## Imputación de valores faltantes

Antes de realizar la imputación, vamos a proceder a eliminar columnas que no ofrecen ninguna información para la imputación de estas variables y la razón por la que se elimina:

* `rating_count_tot`: Esta es la variable respuesta, la que queremos predecir con nuestro modelo. Por lo tanto, la eliminamos ya que de no hacerlo se genera una dependencia circular entre los valores imputados y los que intentamos predecir.
* `rating_count_ver`: Esta variable es un subconjunto de la anterior, ya que hace referencia al número de valoraciones
recibidas para la última versión.
* `X`: es el índice de la fila en la tabla.
* `track_name`: El nombre de la aplicación en el *App Store*.
* `currency`: divisa, decidimos eliminar esta variable por tener un porcentaje tan alto de valores faltantes.
* `ver`: Versión de la aplicación. Como no tiene porqué seguir un estándar, carece de significado.

```{r eliminar_columnas}
data_train_imputacion <- subset(data_train, select=-c(rating_count_tot, rating_count_ver, X, track_name, currency, ver))
```

### Imputación usando el paquete MICE

Para realizar la imputación de valores faltantes de las variables `user_rating` y `user_rating_ver` hemos usado el paquete MICE, que incluye múltiples métodos para imputar estos valores. Nosotros hemos aplicado el método `cart`. Este método se basa en árboles de clasificación y regresión. Los modelos CART (*Classification and regression trees*) buscan predictores y puntos en estos predictores donde dividir la muestra. Estos puntos dividen la muestra en más sub-muestras homogéneas, y este proceso se repite en las sub-muestras hasta que una serie de divisiones define un árbol binario. Si la variable objetivo es discreta, será un árbol de clasificación mientras que si es continua será un árbol de regresión.

El parámetro `m` indica el número de imputaciones que se van a realizar para poder elegir cuál es la que finalmente se aplica. En este caso, `m` vale 1 ya que sólo queremos que la imputación se realice una vez.

```{r imputacion_datos}
# Semilla
set.seed(1)

train_imputed  = mice(data_train_imputacion, method = "cart", m = 1, seed = 1)
summary(train_imputed)
```

```{r}
# Semilla
set.seed(1)

data_train_imputacion <- complete(train_imputed)
```

Cálculo del error cuadrático medio para las variables imputadas:
```{r}
# Creamos sub-dataframes con las columnas que nos interesa para comparar los valores obtenidos
compare_imp_ur <- cbind(data_train_original$user_rating, data_train$user_rating, data_train_imputacion$user_rating)
compare_imp_urv <- cbind(data_train_original$user_rating_ver, data_train$user_rating_ver, data_train_imputacion$user_rating_ver)
compare_imp_lang <- cbind(data_train_original$lang.num, data_train_imputacion$lang.num)

colnames(compare_imp_ur) <- c("user_rating_orig", "user_rating_na", "user_rating_imputado")
compare_imp_ur <- as.data.frame(compare_imp_ur)

colnames(compare_imp_urv) <- c("user_rating_ver_orig", "user_rating_ver_na", "user_rating_ver_imputado")
compare_imp_urv <- as.data.frame(compare_imp_urv)

colnames(compare_imp_lang) <- c("lang_num_orig", "lang_num_imputado")
compare_imp_lang <- as.data.frame(compare_imp_lang)
```

Puesto que tenemos los valores originales de las columnas donde hemos simulado los datos faltantes, podemos obtener una medida de cómo 
de aproximada ha sido la imputación. La medida que hemos elegido es el error cuadrático medio:

```{r}
# Definimos función para calcular el error cuadrático medio
calcular_error_cuad_medio <- function(df, orig, imputado) {
  difsq <- (orig - imputado)^2
  rss <- sum(difsq)/length(difsq)
  rss
}

# Calculamos el error cuadrático medio de los valores que hemos imputado
rss_user_rating <- calcular_error_cuad_medio(compare_imp_ur, compare_imp_ur$user_rating_orig, compare_imp_ur$user_rating_imputado)
rss_user_rating_ver <- calcular_error_cuad_medio(compare_imp_urv, compare_imp_urv$user_rating_ver_orig,
                                                 compare_imp_urv$user_rating_ver_imputado)


comparar_rss <- cbind(rss_user_rating, rss_user_rating_ver)
colnames(comparar_rss) <- c("user_rating", "user_rating_ver")
as.data.frame(comparar_rss)
```


Para la variable del número de idiomas podemos observar los valores imputados, pero no compararlos ya que en este caso no tenemos el valor original:

```{r}
compare_imp_lang %>% 
  filter(is.na(lang_num_orig))
```

```{r}
# Añadimos columnas imputadas a nuestro conjunto de train
data_train <- data_train %>%
  mutate(user_rating = data_train_imputacion$user_rating) %>%
  mutate(user_rating_ver = data_train_imputacion$user_rating_ver) %>%
  mutate(lang.num = data_train_imputacion$lang.num)
```

## Comparación de los valores imputados contra los datos reales


# Transformación de variables cuantitativas

Procederemos a analizar las variables cuantitativas del data set, de esta manera estudiaremos su comportamiento con el fin de relacionar patrones y poder ajustar su escala (en caso de que sea necesario) con el fin de visualizar mejor su distribución.


## Variable rating_count_tot

El *rating_count_tot* que representa el total de calificaciones o reseñas otorgadas a la aplicación de distribuye de la siguiente manera.


```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(data=data_train, aes(x=rating_count_tot))+
  geom_histogram(bins=100, color='steelblue', fill='steelblue')+
  labs(x = "Numero de Calificaciones total", y ="Frecuencia" , title = "HISTOGRAMA NÚMERO DE CALIFICACIONES TOTALES")+
  theme(plot.title = element_text(hjust = 0.5, face="bold", size =12), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 10, angle = 45, hjust = 1), axis.text.y = element_text(size = 10))
```


Para poder apreciar su distribución aplicaremos un logaritmo que nos permita apreciar mayormente su distribución.

```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(data=data_train, aes(x=log10(rating_count_tot)))+
  geom_histogram(bins=10, color='steelblue', fill='steelblue')+
  labs(x = "Numero de Calificaciones total", y ="Frecuencia" , title = "HISTOGRAMA NÚMERO DE CALIFICACIONES TOTALES", subtitle = "Log")+theme(plot.title = element_text(hjust = 0.5, face="bold", size =12), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 10, angle = 45, hjust = 1), axis.text.y = element_text(size = 10))
```

Es importante recalcar, que de no haber eliminado al inicio los valores cuyo rating_count_tot correspondian a 0, al aplicar logaritmo se hubieran eliminado de igual manera, aun asi, lo mejor era eliminarlo y trabajar en función de los datos de interés. Puesto que son pocas observaciones, estos valores 0 no son suficientes como para tener un modelo adicional.

Analizamos los cuantiles de los datos.

```{r}
quantile(data_train$rating_count_tot, probs = seq(0,1,0.05))
```


Podemos notar que el comportamiento de *rating_count_tot* varia drásticamente, el salto entre el cuantil 95% al 100% varia desde 48107 a 2974676.

Solo el 0.13% de los datos representan valores mayores de mas del millón.


```{r}
top_10 <- data_train %>% top_n(10, rating_count_tot)
(nrow(top_10)/nrow(data_train))*100
```

Añadimos la variable transformada al data_train ya que esta distribución nos permitira trabajar con el modelo de una manera mas eficiente.


```{r}
data_train <- data_train %>%
  mutate(rating_count_tot_new = log10(rating_count_tot))
```


## Variable Size_bytes

La principal problemática que nos genera esta variable es la comprensión de los datos. Para hacerlos comprensibles para todas las personas, a través de la función “Hsize” se transforma  la medida de bytes a  Mb para que sea más legible.

```{r include=FALSE}
Mb <- data.frame(data_train$X, data_train$size_bytes)
names(Mb)[names(Mb) == "data_train.X"] <- "X"
names(Mb)[names(Mb) == "data_train.size_bytes"] <- "size_bytes"

# Transformamos la variable de bytes a Mb

size <- hsize(Mb$size_bytes, standard="SI")
Mb$size_MB <- as.numeric(str_replace(size, " MB", ""))

Mb <- select(Mb, X, size_MB)
head(Mb)
# Unimos la nueva columna al Dataframe original
data_train <- merge (x=data_train, y=Mb, by="X")
```

```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(data_train, aes(x=size_bytes)) +
  geom_histogram(bins=10, fill='steelblue')+
 labs(x = "Peso de la Aplicación" , y ="Frecuencia" , title = "HISTOGRAMA PESO DE LA APLICACIÓN")+ theme(plot.title = element_text(hjust = 0.5, face="bold", size =12), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 10, angle = 45, hjust = 1), axis.text.y = element_text(size = 10))
```

Observamos que la mayoría se encuentra ubicada hacia el cero, por ende aplicaremos un logaritmo y así poder apreciar su distribución

```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(data_train, aes(x=log10(size_bytes))) +
  geom_histogram(bins=10, fill='steelblue')+
  labs(x = "Peso de la Aplicación" , y ="Frecuencia" , title = "HISTOGRAMA PESO DE LA APLICACIÓN", subtitle = "Log10")+ theme(plot.title = element_text(hjust = 0.5, face="bold", size =12), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 10, angle = 45, hjust = 1), axis.text.y = element_text(size = 10))
```

Al igual que la variable anterior, su distribución se "normaliza" un poco. 
 
Añadimos la variable transformada al data_train

```{r}
data_train <- data_train %>%
  mutate(size_bytes_new = log10(size_bytes))
```

## Variable sup_devices.num

```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(data_train, aes(x=sup_devices.num))+
  geom_histogram(bins=10, fill='steelblue')+
  labs(x = "dispositivos Soportados" , y ="Frecuencia" , title = "HISTOGRAMA DISPOSITIVOS SOPORTADOS")+ theme(plot.title = element_text(hjust = 0.5, face="bold", size =12), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 10, angle = 45, hjust = 1), axis.text.y = element_text(size = 10))
```

Al aplicar potencia cuadrada a esta variable observamos un poco mejor aquellos valores cercanos al cero, sin embargo aún asi al prevalecer los valores entre el 35-40 es inevitable esta distribución

```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(data_train, aes(x=(sup_devices.num)**2))+
  geom_histogram(bins=30, fill='steelblue')+
  labs(x = "Dispositivos Soportados" , y ="Frecuencia" , title = "HISTOGRAMA DISPOSITIVOS SOPORTADOS", subtitle = "x^2")+ theme(plot.title = element_text(hjust = 0.5, face="bold", size =12), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 10, angle = 45, hjust = 1), axis.text.y = element_text(size = 10))
```

Transformamos la variable elevando al cuadrado para visualizar mejor sus valores hacia la izquierda.


Añadimos la variable transformada al data_train

```{r}
data_train <- data_train %>%
  mutate(sup_devices_new = (sup_devices.num)**2)
```

## Variable lang.num

```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(data_train, aes(x=(lang.num))) +
  geom_histogram(bins=10, fill='steelblue')+
  labs(x = "Nº de Idiomas" , y ="Frecuencia" , title = "HISTOGRAMA Nº IDIOMAS", subtitle = "log10")+ theme(plot.title = element_text(hjust = 0.5, face="bold", size =12), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 10, angle = 45, hjust = 1), axis.text.y = element_text(size = 10))
```



```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(data_train, aes(x=log10(1+(lang.num)))) +
  geom_histogram(bins=10, fill='steelblue')+
  labs(x = "Nº de Idiomas" , y ="Frecuencia" , title = "HISTOGRAMA Nº IDIOMAS", subtitle = "log10+1")+ theme(plot.title = element_text(hjust = 0.5, face="bold", size =12), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 10, angle = 45, hjust = 1), axis.text.y = element_text(size = 10))
```

Añadimos la variable transformada al data_train

```{r}
data_train <- data_train %>%
  mutate(lang.num_new = log10(1+(lang.num)))
```

## Variable Screen Shot

```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(data_train, aes(x=(data_train$ipadSc_urls.num))) +
  geom_histogram(bins=10, fill='steelblue')+
  labs(x = "Nº de Idiomas" , y ="Frecuencia" , title = "HISTOGRAMA CAPTURA DE PANTALLA")+ theme(plot.title = element_text(hjust = 0.5, face="bold", size =12), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 10, angle = 45, hjust = 1), axis.text.y = element_text(size = 10))
```

# Procesado de variables cualitativas

## Rating de edad

Existe una clasificación de contenido para las aplicaciones, los estándares más importantes son: A nivel europeo “PEGI” y a nivel americano “ESRB”. Las principales distribuidoras de aplicaciones para móviles, cómo son Apple Store o Google Play, siguen una clasificación diferente.

```{r include=FALSE}
# Nos quedamos con la variable objetivo y un identificador para integrarlo con la origen tras procesar la variable
Rating <- data.frame(data_train$X, data_train$cont_rating)

names(Rating)[names(Rating) == "data_train.X"] <- "X"
names(Rating)[names(Rating) == "data_train.cont_rating"] <- "cont_rating"
```

### Análisis de la variable.

En el caso que nos ocupa es el de Apple Store, que establece 4 clasificaciones:

```{r}
unique(Rating$cont_rating)
```

### Primer nivel: 4+
- No contiene material objetable, por lo que pueden ser consumidas por niños de hasta 11 años.

### Segundo nivel: 9+
- Puede contener ocurrencias leves o infrecuentes de dibujos animados, fantasía o violencia realista, y contenido maduro, sugerente o temático de terror, leve o infrecuente, que puede no ser adecuado para niños menores de 9 años.

### Tercer nivel: 12+
- Puede contener dibujos animados frecuentes o intensos, fantasía o violencia realista, temas maduros o sugestivos leves o infrecuentes, mal lenguaje suave o infrecuente, y juegos de azar simulados que pueden no ser adecuados para niños menores de 12 años.

### Último nivel: 17 +
- Puede contener lenguaje ofensivo frecuente e intenso, caricaturas excesivas, fantasía o violencia realista, madurez frecuente e intensa, horror, temas sugestivos, contenido sexual, desnudez, alcohol y drogas, o una combinación de cualquiera de estos factores que son inadecuados para personas menores de 17 años de edad. Esto incluye aplicaciones con acceso web sin restricciones. Ninguna persona menor de 16 años puede comprar una aplicación con una calificación de 17+.

Para conocer mejor nuestra variable, utilizaremos la función ‘Table’ y una gráfica ‘plot’ para ver la distribución de la misma en nuestros datos:


```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(Rating, aes(x=cont_rating)) + geom_bar(fill='lightsteelblue2')+
  labs(x = "Rating de la App" , y ="Frecuencia" , title = "Rating por Edad")+ theme(plot.title = element_text(hjust = 0.5, face="bold", size =12), plot.subtitle =element_text(hjust = 0.5, face ="bold", size=10), axis.text.x = element_text(size = 10, hjust = 1), axis.text.y = element_text(size = 10))
```

Observamos que la mayoría de las aplicaciones en Apple Store tienen una clasificación de 4+, es decir, son aptas para todos los públicos, mientras que las que mayor clasificación tienen 17+, son las minoritarias.

### Procesado de la variable

Para realizar un análisis de regresión, todas las variables deben ser numéricas, por lo que dicha variable requiere una recodificación. La recodificación utilizada en este caso se basa en los 4 niveles de rating, por cada nivel crearemos una nueva variable con dos niveles cada una:

#### Categoría_4+.
1, cuando la aplicación está categorizada por 4+.
0, cuando la aplicación no está categorizada como 4+.

#### Categoría_9+.
1, cuando la aplicación está categorizada por 9+.
0, cuando la aplicación no está categorizada como 9+.

#### Categoría_12+.
1, cuando la aplicación está categorizada por 12+.
0, cuando la aplicación no está categorizada como 12+.

#### Categoría_17+.
1, cuando la aplicación está categorizada por 17+.
0, cuando la aplicación no está categorizada como 17+.

```{r}
# Categorizamos la variable en los 4 niveles.
# Cargamos los paquetes dummies
data_train <- cbind(data_train, dummy(data_train$cont_rating))
#Rename
names(data_train)[names(data_train) == "data_train17+"] <- "rating_17"
names(data_train)[names(data_train) == "data_train12+"] <- "rating_12"
names(data_train)[names(data_train) == "data_train9+"] <- "rating_9"
names(data_train)[names(data_train) == "data_train4+"] <- "rating_4"
```

## Variable Prime_genre

En la plataforma de Apple Store, se dividen las aplicaciones en 23 clasificaciones dependiendo del género de las mismas.

```{r include=FALSE}
genero <- data.frame(data_train$X, data_train$prime_genre)

names(genero)[names(genero) == "data_train.X"] <- "X"
names(genero)[names(genero) == "data_train.prime_genre"] <- "genero"
```

```{r}
unique(genero$genero)
```

### Análisis de la variable.

Para conocer más la variable y cómo análisis exploratorio de la misma, generamos el número de aplicaciones por género, además de un porcentaje sobre el total de aplicaciones.


```{r}
genero_tab<- data.frame(table(genero$genero))
genero_tab = mutate(genero_tab, percent = Freq/ sum(Freq))
names(genero_tab)[names(genero_tab) == "Var1"] <- "genero"
genero_tab
```


```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(genero_tab, aes(x="", y=Freq, fill=genero)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0)+
  labs(title = "Genero de la App")+
  theme(plot.title = element_text(hjust = 0.5, face="bold", size =12))
```

Cómo podemos observar en la gráfica siguiente, el género que mayor tasa de aplicaciones es el género “Games” con un 50% de las aplicaciones. El resto de las aplicaciones se dividen entre las 22 categorías de Apple Store. Debido a esta problemática, optaremos por crear cuatro nuevas clasificaciones partiendo de las clasificaciones de la tienda oficial de Apple. Estas nuevas categorías son:

1. Games.
2. Lifestyle.
3. Utilities.
4. Entertainment.

```{r}
#Creamos las 4 categorías.

genero$genero_new <- 0
genero$genero_new [genero$genero == 'Games'] <-"Games"
genero$genero_new [genero$genero == 'Business'       |genero$genero == 'Catalogs'
                 |genero$genero == 'Education'       |genero$genero == 'Finance'
                 |genero$genero == 'Health & Fitness'|genero$genero == 'Lifestyle'
                 |genero$genero == 'Medical'         |genero$genero == 'Sports'
                 |genero$genero == 'Travel']<- "Lifestyle"

genero$genero_new [genero$genero == 'Utilities' |genero$genero == 'Weather'
                 |genero$genero == 'Navigation' |genero$genero == 'Productivity'
                 |genero$genero == 'Reference' ]<- "Utilities"

genero$genero_new [genero$genero == 'Entertainment'|genero$genero == 'Book'
                 |genero$genero == 'Food & Drink'  |genero$genero == 'Music'
                 |genero$genero == 'News'          |genero$genero == 'Photo & Video'
                 |genero$genero == 'Shopping'      |genero$genero =='Social Networking'
                 ]<- "Entertainment"
genero_new <- select(genero,X, genero_new)
unique(genero_new$genero_new)
```

```{r}
# Analizamos la nueva variable
genero_new<- data.frame(table(genero_new$genero_new))
genero_new = mutate(genero_new, percent = Freq/ sum(Freq))
names(genero_new)[names(genero_new) == "Var1"] <- "genero"
genero_new
```

Las nuevas categorías presentan una distribución diferente, donde encontramos que el género “Games” sigue siendo el mayoritario en nuestros datos, seguido del género “Entertainment” y “Lifestyles”. El género con menor número de aplicaciones es “Utilities”.

```{r, warning= FALSE, fig.align='center', fig.show='hold', fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(genero_new, aes(x="", y=Freq, fill=genero)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0)+
  labs(title = "Genero de la App")+
  theme(plot.title = element_text(hjust = 0.5, face="bold", size =12))
```

### Procesado de la variable.

El procesado de esta variable se llevará a cabo creando 4 nuevas columnas dentro de nuestro datasets origen, para cada nuevo género.

Games_genre:
  1, cuando la aplicación está categorizada como “Juegos”.
  0, cuando la aplicación no está categorizada como “Juegos”.

Entertainment_genre:
  1, cuando la aplicación está categorizada como “Entretenimiento”.
  0, cuando la aplicación no está categorizada como “Entretenimiento”.

Utilities_genre:
  1, cuando la aplicación está categorizada como “Utilidades”.
  0, cuando la aplicación no está categorizada como “Utilidades”.

Lifestyle_genre:
  1, cuando la aplicación está categorizada como “Estilo de vida”.
  0, cuando la aplicación no está categorizada como “Estilo de vida”.


```{r warning=FALSE}
# Integramos con Apple_Store y creamos una columna para cada categoría.

genero <- select(genero,X, genero_new)
data_train <- merge (x= data_train, y=genero, by="X")

data_train <- cbind(data_train, dummy(data_train$genero_new))
names(data_train)[names(data_train) == "data_trainGames"] <- "Games_genre"
names(data_train)[names(data_train) == "data_trainLifestyle"] <- "Lifestyle_genre"
names(data_train)[names(data_train) == "data_trainEntertainment"] <- "Entertainment_genre"
names(data_train)[names(data_train) == "data_trainUtilities"] <- "Utilities_genre"
```

```{r}
data_train_new <- data_train %>% select(
  4,6,7,8,12,14,16,17,18,19,20,21,22,24,25,26,27)
```

```{r}
head(data_train_new)
```

## Variable price

Al tener tantos valores faltantes en la columna de `currency` (la divisa), optamos por crear una variable binaria que nos diga si la aplicación es de pago (1) o es gratuita (0).

```{r}
data_train$de_pago <- ifelse(data_train$price>0, 1, 0)
```

# Selección de variables

Para seleccionar qué variables son las más significativas para nuestro modelo, aplicamos uno de los métodos para obtenerlas automáticamente evaluándolas con uno de los parámetros propuestos. En este caso, usamos "R cuadrado ajustado".

```{r echo=TRUE}
# Semilla
set.seed(1)

# Eliminamos la variable original del género y nos quedamos con la transformada

data_train_clean <- data_train %>%
  select(-c(track_name, ver, cont_rating, currency, prime_genre, rating_count_tot, rating_count_ver, X, id))
```

Usamos el método "Forward" para realizar la selección automática de variables. Nos basamos en el valor de R-cuadrado ajustado.

```{r echo=FALSE, warning=FALSE}
# Semilla
set.seed(1)

# Forward
regfit_full_fwd <- leaps::regsubsets(rating_count_tot_new~., data_train_clean, method='forward')

reg_sum_fwd <- summary(regfit_full_fwd)

plot(regfit_full_fwd, scale="adjr2")
```

```{r}
data_coef_fwd <- coef(regfit_full_fwd, 9)
as.data.frame(data_coef_fwd)
```

# Ajuste, interpretación y diagnosis del modelo de regresión lineal múltiple

## Definición del modelo

```{r warning=FALSE}
data_train_modelo_fwd <- data_train_clean %>%
  select(rating_count_tot_new, user_rating, user_rating_ver, ipadSc_urls.num,
         size_bytes_new, lang.num_new, `rating_12`, `rating_9`, Lifestyle_genre, Utilities_genre)
```

```{r}
# Semilla
set.seed(1)

# Modelo
lm_fit <- lm(rating_count_tot_new~., data=data_train_modelo_fwd)
summary(lm_fit)
```

Utilizaremos el método Forward que al igual que los otros métodos utilizados forman parte de las estrategias de regresión gradual, la cuál consiste en la agregación y eliminación de los predictores, en búsca de encontrar el subconjunto de variables con mayor rendimiento para el modelo.

En el caso del modelo elegido, los predictores se van agregando según su contribución al modelo y se maximiza el resultado con la mayor significación obtenida. Al generar el modelo Forward, encontramos los siguientes resultados:

Nivel de significación:

- Encontramos 4 variables significativas al 0, lo que significa un alto grado de evidencia estadística, entre ellas se encuentra: La variable “User_rating”, “User_rating_ver”, “Lang.num_new”, “rating_12”.
- Además, las variable “Rating_9” es significativa en un menor grado que las anteriormente nombradas, aunque con un alto grado de significación.

Por lo que, la seleción de variables automática nos daría cómo resultado estas 6 variables:

1.  User_rating.
2.  User_rating_ver.
3.  lang.num_new
4.  Rating_12
5.  Rating_9

R ajustado:
Hemos obtenido la cifra de 0.153, el cuál establece el grado de intensidad de las variables independientes, por lo que la variable dependiente, en nuestro caso “Rating_count_tot_new”, es explicada al 15.3% por las variables selecionadas.

## Interpretación de resultados

Para interpretar los resultados que hemos obtenido tras aplicar el modelo, vamos a comentar la información que nos da la función `summary`:

* Residuals (residuos): Estos residuos son el error entre la predicción del modelo y los valores reales. Cuanto menor sea su valor, mejor.

* Coefficients (coeficientes): Para cada variable introducida en el modelo y el `intercept` (término independiente), se produce un peso que tiene más información, como el error estándar, un valor t-test y la significancia.

* Estimate (estimación): Este es el peso otorgado a la variable.

* Std. Error (error estándar): Dice cómo de precisa ha sido la estimación. Se usa para calcular el t-valor.

* t-value y Pr(>[t]): El t-valor se calcula dividiendo el coeficiente entre el error estándar. Se usa para probar si el coeficiente es significativamente distinto de cero. Si no lo es, quiere decir que este coeficiente no añade nada al modelo y podría ser descartado o re-evaluado. Pr(>|t|) es el nivel de significatividad (significance).

* Medidas de rendimiento: Se proporcionan tres conjuntos de medidas:

  * Residual Standard Error (Error estándar de los residuos).
  * Multiple / Adjusted R-Square (R-cuadrado ajustado): El parámetro R-cuadrado refleja la bondad del ajuste de un modelo a la variable que pretendes explicar. Su valor oscila entre 0 y 1. Cuanto más cerca de 1 se sitúe su valor, mayor será el ajuste del modelo a la variable que estamos intentando explicar. El R-cuadrado ajustado tiene en cuenta el número de variables (útil para regresión múltiple).
  * F-Statistic: El F-test comprueba si al menos el peso de una variable es significativamente distinto de cero. Si el p-valor no es significativo (por ejemplo, mayor de 0.05), entonces el modelo no sirve.
  
## Diagnósis del modelo

Para comprobar si el modelo es válido, debemos analizar los residuos:

```{r}
# Histograma: distribución de residuos
hist(lm_fit$resid, main="Histograma de los residuos", ylab="Residuos")
```

Además deberíamos comprobar lo siguiente: 
* La media de los residuos es cero y también la suma de estos.
* Los residuos se distribuyen normalmente.
* Los residuos son independientes.
* Los residuos tienen varianza constante (Homocedasticidad).

De los puntos anteriores hemos comprobado si los residuos de sitribuyen normalmente o no y si son independientes.

### Normalidad.

```{r}
#Q-Q Plot
qqnorm(lm_fit$resid)
qqline(lm_fit$resid)

# Contraste de normalidad
sw_test <- shapiro.test(lm_fit$resid)
```

### Independencia

```{r}
dwtest(lm_fit) #Test for independence of residuals
```


