---
title: "Práctica Métodos de Análisis de datos"
author: "Edgli Morales, David Ruiz y Miguel Ángel Fernández - Máster en Data Science, URJC"
date: "Diciembre de 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r init, include=FALSE}
# Cargamos los paquetes que vamos a usar en el informe
library(dplyr)
library(tidyr)
library(ggplot2)
library(egg)
library(GGally)

library(ISLR)
library(car)
library(DMwR2)
library(faraway)
library(mlbench)

library(knitr)
library(kableExtra)
library(htmltools)
library(bsplus)
library(RColorBrewer)
library(VIM)
library(mice)

# Koki
library(data.table)
library(corrplot)
library(GGally)
library(tidyverse)
library(PerformanceAnalytics)
library(plotly)

# Usados por david
install.packages('R.methodsS3')
library(R.methodsS3)
library(R.oo)
# Seed
set.seed(3)
```

# Introducción 

El conjunto de datos que se analiza en esta práctica trata sobre información acerca de aplicaciones móviles disponibles en el *App Store*, la tienda de aplicaciones de *Apple*.

```{r read_file}
data_apps = read.csv("AppleStore.csv")
```

# Valores faltantes

Al realizar un análisis preliminar de los datos, observamos que no hay valores faltantes. 
```{r comprobar_na}
sum(is.na(data_apps))
```

Antes de empezar a trabajar con los datos en más profundidad, vamos a simular estos datos faltantes. Primero, vamos a generar un gran porcentaje de valores faltantes en una de las variables, "`currency`", que indica la divisa del precio de la aplicación. El procentaje de valores faltantes será en este caso de un 80\%.

```{r generate_missing_currency}
num_filas <- nrow(data_apps)
porcentaje_missing <- 80
num_missing <- round((num_filas * porcentaje_missing)/100)
pos_missing <- sort(sample(1:num_filas, num_missing, replace=FALSE))

data_apps$currency[c(pos_missing)] <- NA
```

Aunque en los datos originales todos los valores de esta columna son `USD` (dólares estadounidenses), simulamos que nos faltan tantos valores de esta variable que la hace prácticamente inusable en cuanto a la información que nos proporciona.

En una situación en la que tenemos datos del precio pero no sabemos la divisa en la que está ese valor, hemos decidido crear una variable categorizando las aplicaciones como gratuitas o de pago.

A continuación, generamos valores faltantes en las variables `user_rating` y `user_rating_ver`, que describen la valoración media de los usuarios en estrellas (valor de 0 a 5) para todas las versiones de la aplicación y sólo para la última versión, respectivamente.

En este caso, generamos un 12\% de valores faltantes para `user_rating` y un 8% para `user_rating_ver`.

```{r generate_missing_user_rating}
num_filas <- nrow(data_apps)
porcentaje_missing <- 12
num_missing <- round((num_filas * porcentaje_missing)/100)

pos_missing <- sort(sample(1:num_filas, num_missing, replace=FALSE))
data_apps$user_rating[c(pos_missing)] <- NA

porcentaje_missing <- 8
num_missing <- round((num_filas * porcentaje_missing)/100)

pos_missing <- sort(sample(1:num_filas, num_missing, replace=FALSE))
data_apps$user_rating_ver[c(pos_missing)] <- NA
```

Una vez que hemos generado los valores faltantes, vamos a representar estos valores en un histograma y cómo se distribuyen en el conjunto.

```{r repr_valores_missing}
aggr_plot <- aggr(data_apps, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE,
                  labels=names(data_apps), cex.axis=.7, gap=3, 
                  ylab=c("Histograma de datos faltantes","Patrón"))
```

(Comentar los gráficos)

```{r repr_variables_missing}
data_apps %>% select(user_rating, user_rating_ver) %>% marginplot()
```

(Comentar los gráficos)

## Imputación de valores faltantes

Primero, eliminamos las columnas que no nos interesan:
```{r eliminar_columnas}
data_apps_clean <- data_apps %>%
  select(-c(track_name, currency, ver, vpp_lic))
```

### Prueba de imputación por K-NN
```{r repr_imputacion_knn}
data_apps_clean %>% select(user_rating, user_rating_ver) %>% VIM::kNN() %>% marginplot(., delimiter="_imp")
```


### Imputación usando el paquete MICE

```{r imputacion_datos}
apps_imp = mice(data_apps_clean, method = "cart", m = 1)
```

```{r}
data_apps_imp <- complete(apps_imp)
```

# Generear conjuntos de entrenamiento, test y validación 

```{r separar_training_test}

# Separamos los datos en los siguientes porcentajes: Train (50), Test (25), Validación (25)

# Obtenemos la muestra del 50% y filtramos por esos elementos
train = sample(1:nrow(data_apps_clean), .5 * nrow(data_apps_clean), replace = FALSE)
data_train = data_apps_clean[train,]

# Cogemos el 50% restante y lo dividimos en dos partes iguales para Test y para Validación
test_validacion = data_apps_clean[-train,]
test = sample(1:nrow(test_validacion), .5 * nrow(test_validacion), replace = FALSE)

# Filtramos para obtener los otros dos conjuntos
data_test = test_validacion[test,]
data_validacion = test_validacion[-test,]
```

# Análisis exploratorio
```{r summary}
summary(data_train)

hist(data_train$user_rating)
```

```{r initial_plots, warning=FALSE}
corrplot(cor(data_train %>% 
               select(price:user_rating_ver, ipadSc_urls.num,
                      sup_devices.num, lang.num, size_bytes), 
               use = "complete.obs"), 
               method = "circle",type = "upper")

stats_apps_cor <- 
  data_train %>% 
  select(price:user_rating_ver, ipadSc_urls.num,
         sup_devices.num, lang.num, size_bytes)
ggpairs(stats_apps_cor)
```
# Procesado de variables cualitativas

### Variable Size_bytes
El principal problema de esta variable es la dificultad de comprensión de los datos, por lo que a través de la transformación dicha variable a MB creamos una nueva variable que sea mas comprensible para el ser humano.
```{r}
Mb <- data.frame(data_train$X, data_train$size_bytes)

names(Mb)[names(Mb) == "data_train.X"] <- "X"
names(Mb)[names(Mb) == "data_train.size_bytes"] <- "size_bytes"

# Transformamos la variable de bytes a Mb

size <- hsize(Mb$size_bytes, standard="SI")
Mb$size_MB <- size

Mb <- select(Mb, X, size_MB)
head(Mb)
# Unimos la nueva columna al Dataframe oroginal
data_train <- merge (x= data_train, y=Mb, by="X")
```
### Rating de edad

La clasificación que sigue apple en este caso, es distinta a la que sigue Google o los sistemas internacionales de clasificación de applicaciones y videojuegos, cómo en el caso europeo "PEGI" o a nivel americano "ESRB", por lo que transformaremos esta variable para que sea más comprensible y para preparar dicha variable para los pasos posteriores.

```{r}
#Nos quedmaos con la variable objetivo y un identificador para mergeralo con la origen tras procesar la variable
Rating <- data.frame(data_train$X, data_train$cont_rating)

names(Rating)[names(Rating) == "data_train.X"] <- "X"
names(Rating)[names(Rating) == "data_train.cont_rating"] <- "cont_rating"
```

Encontramos 4 niveles de rating en Apple store:

```{r}
unique(Rating$cont_rating)
```
#### Primer nivel: 4+
- No contiene material objetable, por lo que pueden ser consumidas por niños de hasta 11 años.

#### Segundo nivel: 9+
- Puede contener ocurrencias leves o infrecuentes de dibujos animados, fantasía o violencia realista, y contenido maduro, sugerente o temático de terror, leve o infrecuente, que puede no ser adecuado para niños menores de 9 años.

#### Tercer nivel: 12+
- Puede contener dibujos animados frecuentes o intensos, fantasía o violencia realista, temas maduros o sugestivos leves o infrecuentes, mal lenguaje suave o infrecuente, y juegos de azar simulados que pueden no ser adecuados para niños menores de 12 años.

#### Último nivel: 17 +
- Puede contener lenguaje ofensivo frecuente e intenso, caricaturas excesivas, fantasía o violencia realista, madurez frecuente e intensa, horror, temas sugestivos, contenido sexual, desnudez, alcohol y drogas, o una combinación de cualquiera de estos factores que son inadecuados para personas menores de 17 años de edad. Esto incluye aplicaciones con acceso web sin restricciones. Ninguna persona menor de 16 años puede comprar una aplicación con una calificación de 17+.

```{r}
# Análisis de la variable
table(Rating$cont_rating)
plot(Rating$cont_rating)
```
Transformamos la variable cualitativa en variable cuantitativa categorizando y asignando un numero del 0 al 4 para cada categoría del Rating de edad. Lo hacemos de esta manera por la naturaleza de la variable origen, ya que ordena del 4+ al 17+ clasificación de edad y la tranformación lo hace de igual manera estableciendo del 1 al 4 dependiendo de la edad de clasificación.

4+ = Categroría Nº1
9+ = Categoría Nº2
12+= Categoría Nº3
17+= Categoría Nº4

```{r}
# Categorizamos la variable en los 4 niveles.

Rating$cat_rating <- 0
Rating$cat_rating [Rating$cont_rating =="4+"]<- 1
Rating$cat_rating [Rating$cont_rating =="9+"]<- 2
Rating$cat_rating [Rating$cont_rating =="12+"]<- 3
Rating$cat_rating [Rating$cont_rating =="17+"]<- 4
Rating %>% distinct(cat_rating, cont_rating)
```

```{r}
Rating <- select(Rating,X, cat_rating)
# Unimos la nueva columna al Dataframe original
data_train <- merge (x= data_train, y=Rating, by="X")
```
### Variable Prime_genre
```{r}
genero <- data.frame(data_train$X, data_train$prime_genre)

names(genero)[names(genero) == "data_train.X"] <- "X"
names(genero)[names(genero) == "data_train.prime_genre"] <- "genero"
```
Dicha variable se divide en varios tipos de applicaciones dependiendo del género de las mismas.Entre ellas encontramos distintas categorías:
```{r}
genero_tab<- data.frame(table(genero$genero))
genero_tab = mutate(genero_tab, percent = Freq/ sum(Freq))
names(genero_tab)[names(genero_tab) == "Var1"] <- "genero"
genero_tab
```

```{r}
pie(genero_tab$Freq, labels = genero_tab$genero)
```
Recategorizamos el género de las aplicaciones en 4 categorías principales, debido a la poca granularidad de la variable:

1. Games.
2. Lifestyle.
3. Ulitilies.
4. Entertainment.

```{r}
#Creamos las 4 categorías.

genero$genero_new <- 0
genero$genero_new [genero$genero == 'Games'] <-"Games"
genero$genero_new [genero$genero == 'Business'       |genero$genero == 'Catalogs'
                 |genero$genero == 'Education'       |genero$genero == 'Finance' 
                 |genero$genero == 'Health & Fitness'|genero$genero == 'Lifestyle'
                 |genero$genero == 'Medical'         |genero$genero == 'Sports'
                 |genero$genero == 'Travel']<- "Lifestyle"

genero$genero_new [genero$genero == 'Utilities' |genero$genero == 'Weather'
                 |genero$genero == 'Navigation' |genero$genero == 'Productivity'
                 |genero$genero == 'Reference' ]<- "Utilities"

genero$genero_new [genero$genero == 'Entertainment'|genero$genero == 'Book'
                 |genero$genero == 'Food & Drink'  |genero$genero == 'Music' 
                 |genero$genero == 'News'          |genero$genero == 'Photo & Video'
                 |genero$genero == 'Shopping'      |genero$genero =='Social Networking'
                 ]<- "Entertainment"
genero_new <- select(genero,X, genero_new)
unique(genero_new$genero_new)
```

```{r}
# Analizamos la nueva variable
genero_new<- data.frame(table(genero_new$genero_new))
genero_new = mutate(genero_new, percent = Freq/ sum(Freq))
names(genero_new)[names(genero_new) == "Var1"] <- "genero"
genero_new
```

```{r}
pie(genero_new$percent, labels =genero_new$genero)
```

## Categorización de la variable Count_Rating
Tras crear las 4 categorías anteriores, crearemos una nueva columna en nuestro datasets por cada categoría, con valores del 1 al 0.
```{r}
# Mergeamos con Apple _Store y creamos una columna para cada categoría.

genero <- select(genero,X, genero_new)
data_train <- merge (x= data_train, y=genero, by="X")

data_train$Game_categ <- 0
data_train$Game_categ [data_train$genero_new == 'Games'] <-1

data_train$Utilities_categ <- 0
data_train$Utilities_categ [data_train$genero_new == 'Utilities'] <-1

data_train$Entertainment_categ <- 0
data_train$Entertainment_categ [data_train$genero_new == 'Entertainment'] <-1

data_train$Lifestyle_categ <- 0
data_train$Lifestyle_categ [data_train$genero_new == 'Lifestyle'] <-1

```

